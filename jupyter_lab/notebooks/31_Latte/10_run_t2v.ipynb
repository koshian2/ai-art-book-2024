{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aaf7662a-ff2b-4dd9-9a03-4a3a236d130f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Ema!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a54b6062568e454e8ba12d6c70de54db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from diffusers.schedulers import PNDMScheduler\n",
    "from diffusers.models import AutoencoderKL, AutoencoderKLTemporalDecoder\n",
    "from diffusers.utils import export_to_gif, export_to_video\n",
    "from transformers import T5EncoderModel, T5Tokenizer\n",
    "from latte_t2v import LatteT2V\n",
    "\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(os.path.split(sys.path[0])[0])\n",
    "from download import find_model\n",
    "from pipeline_videogen import VideoGenPipeline\n",
    "from PIL import Image\n",
    "\n",
    "## == Params ==\n",
    "video_length = 16\n",
    "pretrained_model_path = \"./share_ckpts/t2v_required_models\"\n",
    "t2v_checkpoint_path = \"./share_ckpts/t2v_v20240523.pt\"\n",
    "enable_vae_temporal_decoder = True # これをFalseにするとVAEのVRAM消費を減らせる\n",
    "## =======\n",
    "\n",
    "# torch.manual_seed(args.seed)\n",
    "torch.set_grad_enabled(False)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# LatteT2V\n",
    "transformer_model = LatteT2V.from_pretrained_2d(\n",
    "    pretrained_model_path, \n",
    "    subfolder=\"transformer\", \n",
    "    video_length=video_length)\n",
    "state_dict = find_model(t2v_checkpoint_path)\n",
    "transformer_model.load_state_dict(state_dict)\n",
    "transformer_model.half()\n",
    "\n",
    "# VAE\n",
    "if enable_vae_temporal_decoder:\n",
    "    vae = AutoencoderKLTemporalDecoder.from_pretrained(\n",
    "        pretrained_model_path, \n",
    "        subfolder=\"vae_temporal_decoder\", \n",
    "        torch_dtype=torch.float16)\n",
    "    # tilingもslicingも不可能\n",
    "else:\n",
    "    vae = AutoencoderKL.from_pretrained(\n",
    "        pretrained_model_path, \n",
    "        subfolder=\"vae\", \n",
    "        torch_dtype=torch.float16)\n",
    "    vae.enable_tiling()\n",
    "    vae.enable_slicing()\n",
    "\n",
    "# Encoder\n",
    "tokenizer = T5Tokenizer.from_pretrained(\n",
    "    pretrained_model_path, subfolder=\"tokenizer\")\n",
    "text_encoder = T5EncoderModel.from_pretrained(\n",
    "    pretrained_model_path, \n",
    "    subfolder=\"text_encoder\", \n",
    "    torch_dtype=torch.float16)\n",
    "\n",
    "# set eval mode\n",
    "transformer_model.eval()\n",
    "vae.eval()\n",
    "text_encoder.eval()\n",
    "\n",
    "# Scheduler selection\n",
    "scheduler = PNDMScheduler.from_pretrained(\n",
    "    pretrained_model_path,\n",
    "    subfolder=\"scheduler\",\n",
    "    beta_start=0.0001, \n",
    "    beta_end=0.02, \n",
    "    beta_schedule=\"linear\",\n",
    "    variance_type=\"learned_range\"\n",
    ")\n",
    "\n",
    "videogen_pipeline = VideoGenPipeline(\n",
    "    vae=vae, \n",
    "    text_encoder=text_encoder, \n",
    "    tokenizer=tokenizer, \n",
    "    scheduler=scheduler, \n",
    "    transformer=transformer_model\n",
    ")\n",
    "# videogen_pipeline.to(device)\n",
    "videogen_pipeline.enable_model_cpu_offload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34519b08-f552-4a92-9ac5-97fec12eab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_t2v(text_prompt,\n",
    "            save_base_path,\n",
    "            width=512, height=512,\n",
    "            num_inference_steps=50,\n",
    "            guidance_scale=7.5,\n",
    "            enable_temporal_attentions=True):\n",
    "    \n",
    "    os.makedirs(os.path.dirname(save_base_path), exist_ok=True)\n",
    "\n",
    "    videos = videogen_pipeline(\n",
    "        text_prompt, \n",
    "        video_length=video_length, \n",
    "        height=width, \n",
    "        width=height, \n",
    "        num_inference_steps=num_inference_steps,\n",
    "        guidance_scale=guidance_scale,\n",
    "        enable_temporal_attentions=enable_temporal_attentions,\n",
    "        num_images_per_prompt=1,\n",
    "        mask_feature=True,\n",
    "        enable_vae_temporal_decoder=enable_vae_temporal_decoder\n",
    "    ).video[0] # uint8 tensor video = [B, T, H, W, C]\n",
    "    frames = [Image.fromarray(videos[i].cpu().numpy()) for i in range(videos.shape[0])]\n",
    "\n",
    "    export_to_gif(frames, save_base_path+\".gif\", fps=8)\n",
    "    export_to_video(frames, save_base_path+\".mp4\", fps=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7832ce9c-dee9-4f20-8351-dec07be2099a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa89a54ecd1d47ee97970ef06890cb72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b07f8b6e89534989bb831592908287ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa50af5643e4033bc1dff6de8a29c3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df83932d61bf45b9a726ceb616d00b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14834f9d01c244d789e922c6c3e3dfad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8ee1701c05427cb58330fd1c7e97d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_prompt = [\n",
    "    'Yellow and black tropical fish dart through the sea.',\n",
    "    'Slow pan upward of blazing oak fire in an indoor fireplace.',\n",
    "    'Sunset over the sea.',\n",
    "    'A dog in astronaut suit and sunglasses floating in space.'\n",
    "    'Drone view of waves crashing against the rugged cliffs along Big Sur’s Garay Point beach. The crashing blue waters create white-tipped waves, while the golden light of the setting sun illuminates the rocky shore.',\n",
    "    'A Japanese girl walking along a path, surrounded by blooming oriental cherries, pink petals slowly falling down to the ground.',\n",
    "    'A realistic landscape shot of the Northern Lights dancing over a snowy mountain range in Iceland.'\n",
    "]\n",
    "\n",
    "for i, prompt in enumerate(text_prompt):\n",
    "    run_t2v(prompt, f\"generated/video_{i:02}\") # 15.4->29GB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
